- 后台线程重复检查系统内存的状态,周期性地回写数据。
- 在系统缓存中脏页过多,而内核需要干净页的情况下,将进行显式刷出。

# 概述

同步和交换不能彼此混淆。同步只保证物理内存中保存的数据与后备存储器一致,而交换将导致从物理内存刷出数据,以释放空间,用于优先级更高的事项。在数据从物理内存清除之前,将与相关的后备存储器进行同步。

可能因不同原因、在不同的时机触发不同的刷出数据的机制。

- 周期性的内核线程,将扫描脏页的链表,并根据页变脏的时间,来选择一些页写回。如果系统不是太忙于写操作,那么在脏页的数目,以及刷出页所需的硬盘访问操作对系统造成的负荷之间,有一个可接受的比例。
- 如果系统中的脏页过多(例如,一个大型的写操作可能造成这种情况),内核将触发进一步的机制对脏页与后备存储器进行同步,直至脏页的数目降低到一个可接受的程度。而“脏页过多”和“可接受的程度”到底意味着什么,此时尚是一个不确定的问题,将在下文讨论。
- 内核的各个组件可能要求数据必须在特定事件发生时同步,例如在重新装载文件系统时。

前两种机制由内核线程 pdflush 实现,该线程执行同步代码,而第三种机制可能由内核中的多处代码触发。

sync_sb_inodes：负责同步属于给定超级块的所有脏的inode，对每个inode都使用 writeback_single_inode 。

术语方面有个需要注意的地方:下文提到inode同步时,总是既包括inode元数据的同步,也包括inode管理的二进制裸数据的同步。对普通文件来说,这意味着同步代码不仅要传输时间戳、属性等信息,还要将文件的内容传输到底层块设备。

# pdflush机制

pdflush机制实现在一个文件中:mm/pdflush.c 。

pdflush 是用通常的内核线程机制启动的:

```c
static void start_one_pdflush_thread(void)
{
	kthread_run(pdflush, NULL, "pdflush");
}
```

并发 pdflush 线程数目的上下限分别定义为 MIN_PDFLUSH_THREADS (2)和 MAX_PDFLUSH_THREADS (8),内核总是遵守这两个限制。

# 启动新线程

pdflush机制由两个主要部分构成,数据结构描述线程的工作,策略例程帮助执行工作。

```c
<mm/pdflush.c>
struct pdflush_work {
	struct task_struct *who;	/* The thread */
	void (*fn)(unsigned long);	/* A callback function */
	unsigned long arg0;		/* An argument to the callback */
	struct list_head list;		/* On pdflush_list, when idle */
	unsigned long when_i_went_to_sleep;
};
```

- who 是一个指针,指向内核线程的 task_struct 实例,该实例用于在进程表中表示特定的pdflush 实例。
- 几个 pdflush_work 的实例,可以使用 list 链表元素,群集到一个标准的双链表上。内核使用全局变量 pdflush_list作为表头
- when_i_went_to_sleep 成员的名称很长,该成员存储了线程上一次进入睡眠的时间。该值可用于从系统删除多余的 pdflush 线程(即在内存中已经有一段比较长的时间处于空闲状态的线程)。
- fn 函数指针(连同 arg0 )是该结构的主干。它指向了完成实际工作的函数。在调用该函数时,arg0作为参数传递。

通过对 fn 使用不同的函数指针,内核能够将各种同步例程集成到 pdflush 框架中,以便为手头的工作选择正确的例程。

# 线程初始化

pdflush 用作内核线程的工作过程。在创建之后, pdflush 线程进入睡眠,直至内核的其他部分为线程指派任务,任务由 pdflush_work 描述。

pdflush-->__pdflush:

- 线程的 pdflush_work 实例添加到全局链表 pdflush_list
- when_i_went_to_sleep 设置为当前系统时间,单位为 jiffies ,记录线程线程开始睡眠的时间。
- 调用 schedule ,这是最重要的操作。因为线程的状态此前设置为 TASK_INTERRUPTIBLE ,线程现在将进入睡眠,直至被外部事件唤醒。
- 工作函数是通过保存的参数调用的,这样它可以着手进行工作。
- 在工作函数结束时,内核将检查工作线程是否太多或太少。如果已经有1秒多的时间没有空闲工作线程 2 ,则 start_one_pdflush_thread 创建一个新线程。如果睡眠时间最长的线程(在pdflush_list 链表末尾)已经睡眠超过1秒,则退出无限循环,这使得当前线程被从系统删除。在这种情况下,除了锁处理之外,唯一需要的清理操作就是对 nr_pdflush_threads 减1,因为少了一个可用的 pdflush 线程。

# 执行实际工作

pdflush_operation 为 pdflush 线程指定了一个工作函数,并唤醒该线程。如果没有可用的线程,则返回−1。否则,从链表移除一个线程并唤醒。

```c
<mm/pdflush.c>
int pdflush_operation(void (*fn)(unsigned long), unsigned long arg0)
{
	unsigned long flags;
	int ret = 0;

	BUG_ON(fn == NULL);	/* Hard to diagnose if it's deferred */

	spin_lock_irqsave(&pdflush_lock, flags);
	if (list_empty(&pdflush_list)) {//为空
		spin_unlock_irqrestore(&pdflush_lock, flags);
		ret = -1;
	} else {
		struct pdflush_work *pdf;

		pdf = list_entry(pdflush_list.next, struct pdflush_work, list);
		list_del_init(&pdf->list);
		if (list_empty(&pdflush_list))
			last_empty_jifs = jiffies;
		pdf->fn = fn;
		pdf->arg0 = arg0;
		wake_up_process(pdf->who);//唤醒
		spin_unlock_irqrestore(&pdflush_lock, flags);
	}
	return ret;
}
```

# 周期性刷出

早期同步方法的名称是kupdate。该名称会作为某些函数的一部分出现,通常用于描述刷出机制。

周期性地刷出脏的缓存数据需要两个组件:借助 pdflush 机制执行的工作函数,以及定期激活该机制的相关代码。

# 相关的数据结构

mm/page-writeback.c 中的 wb_kupdate 函数负责刷出操作的技术实现。

### 页状态

wb_kupdate 基于两个数据结构,二者控制了该函数的运作。其中一个是全局数组 vm_stat ,可用于查询所有系统内存页的状态。

该数组保存了一组全面的统计信息,用于描述每个CPU的内存页面的状态。因而,系统中的每个CPU都对应该结构的一个实例。各个实例群集在一个数组中,以简化访问。

内核不仅维护了一个全局数组来收集页统计信息,还为各个内存域都提供了同样的信息。

### 回写控制

另一个数据结构保存了用于控制脏页回写的各种数据结构。

```c
<linux/writeback.h>
struct writeback_control {
	struct backing_dev_info *bdi;	/* If !NULL, only write back this
					   queue */
	enum writeback_sync_modes sync_mode;
	unsigned long *older_than_this;	/* If !NULL, only write back inodes
					   older than this */
	long nr_to_write;		/* Write this many pages, and decrement
					   this for each page written */
	long pages_skipped;		/* Pages which were not written */

	/*
	 * For a_ops->writepages(): is start or end are non-zero then this is
	 * a hint that the filesystem need only write out the pages inside that
	 * byterange.  The byte at `end' is included in the writeout request.
	 */
	loff_t range_start;
	loff_t range_end;

	unsigned nonblocking:1;		/* Don't get stuck on request queues */
	unsigned encountered_congestion:1; /* An output: a queue is full */
	unsigned for_kupdate:1;		/* A kupdate writeback */
	unsigned for_reclaim:1;		/* Invoked from the page allocator */
	unsigned for_writepages:1;	/* This is a writepages() call */
	unsigned range_cyclic:1;	/* range_start is cyclic */
};
```

- bdi 指向一个类型为 backing_dev_info 的结构实例,其中总述了有关底层存储介质的信息。我们在这里对两部分比较感兴趣。首先,该结构提供了一个变量来保存回写队列的状态(这意味着,例如,如果写请求太多,则可以通知调用方发生拥塞),其次,它允许标记出基于物理内存的文件系统,此类文件系统没有(块设备作为)后备存储器,回写操作对此类文件系统是无意义的。
- sync_mode 对三种同步模式进行区分:WB_SYNC_NONE:不等待任何东西,WB_SYNC_ALL,:对每个映射都进行等待,WB_SYNC_HOLD:对 sys_sync() ,将inode置于 sb_dirty
- 如果数据变脏的时间已经超过 older_than_this 指定的值,那么将回写。
- nr_to_write 可以限制应该回写的页的最大数目。
- 在回写过程中,因各种原因跳过的页的数目,可通过计数器 pages_skipped 报告给高层
- nonblocking 标志位指定了回写队列在遇到拥塞时是否阻塞。如果被阻塞,则内核将一直等待,直到队列空闲为止。否则,内核将交出控制权。写操作将在稍后恢复。
- encountered_congestion 也是一个标志位,通知高层在数据回写期间发生了拥塞。
- 如果写请求由周期性机制发出,则 for_kupdated 设置为1。否则,其值为0。
- for_reclaim：如果回写操作是由内存回收或 do_writepages 函数发起,则分别设置对应的标志位。
- 如果 range_cyclic 设置为0,则回写机制限于对 range_start 和 range_end 指定的范围进行操作。该限制是对回写操作的目标映射设置的。
- 如果 range_cyclic 设置为1,则内核可能多次遍历与映射相关的页,该成员因此而得名。

### 可调参数

内核支持通过参数对同步操作进行微调，这些参数位于 /proc/sys/vm/ 。有如下4个参数可以设置,都定义在 mm/pagewriteback.c 。

- dirty_background_ratio 指定脏页的百分比,当脏页比例超出该阈值时, pdflush 在后台开始周期性的刷出操作。默认值为10,当与后备存储器相比,有超过10%的页变脏时, pdflush机制将开始运转。
- vm_dirty_ratio (对应的 sysctl 是 dirty_ratio )指定了脏页(相对于非高端内存域)的百分比,脏页比例超出该阈值时,将开始刷出。默认值是40。
- dirty_writeback_interval 定义了周期性刷出例程两次调用之间的间隔(对应的 sysctl 是dirty_writeback_centisecs )。 间 隔的单位是百分之一秒(源代码中也称作厘秒,centisecond)。默认值是500,相当于两次调用的间隔为5秒。
- 一页可以保持为脏状态的最长时间,由 dirty_expire_interval 指定(对应的 sysctl 是dirty_expire_centisecs )。该时间值的单位仍然是百分之一秒。默认值为3 000,这意味着一个脏页在写回之前,保持脏状态的时间最长可达30秒。

# 中央控制

周期性刷出操作中,关键性的一个组件是定义在 mm/page-writeback.c 中的 wb_kupdate 过程。它负责指派底层例程在内存中查找脏页,并将其与底层块设备同步。

```c
<mm/page-writeback.c>

static void wb_kupdate(unsigned long arg)
{
	unsigned long oldest_jif;
	unsigned long start_jif;
	unsigned long next_jif;
	long nr_to_write;
	struct writeback_control wbc = {
		.bdi		= NULL,
		.sync_mode	= WB_SYNC_NONE,
		.older_than_this = &oldest_jif,
		.nr_to_write	= 0,
		.nonblocking	= 1,
		.for_kupdate	= 1,
		.range_cyclic	= 1,
	};

	sync_supers();//同步超级块

	oldest_jif = jiffies - dirty_expire_interval;
	start_jif = jiffies;
	next_jif = start_jif + dirty_writeback_interval;
	nr_to_write = global_page_state(NR_FILE_DIRTY) +
			global_page_state(NR_UNSTABLE_NFS) +
			(inodes_stat.nr_inodes - inodes_stat.nr_unused);//获得回写页的数目
	while (nr_to_write > 0) {
		wbc.encountered_congestion = 0;
		wbc.nr_to_write = MAX_WRITEBACK_PAGES;//每次循环中，回写MAX_WRITEBACK_PAGES个页
		writeback_inodes(&wbc);
		if (wbc.nr_to_write > 0) {//发生拥塞
			if (wbc.encountered_congestion)
				congestion_wait(WRITE, HZ/10);
			else
				break;	/* All the old data is written */
		}
		nr_to_write -= MAX_WRITEBACK_PAGES - wbc.nr_to_write;
	}
	if (time_before(next_jif, jiffies + HZ))
		next_jif = jiffies + HZ;
	if (dirty_writeback_interval)
		mod_timer(&wb_timer, next_jif);
}
```

在 page_writeback_init 初始化了同步层之后,整个机制就开始运转,内核在该函数中第一次启动相关的定时器（mod_timer(&wb_timer, jiffies + dirty_writeback_interval);）

```c
<mm/page-writeback.c>
static DEFINE_TIMER(wb_timer, wb_timer_fn, 0, 0);

static void wb_timer_fn(unsigned long unused)
{
	if (pdflush_operation(wb_kupdate, 0) < 0)
		mod_timer(&wb_timer, jiffies + HZ); /* delay 1 second *//在没有 pdflush 线程可用时。这种情况下,该函数会将下一次 wb_timer_fn 调用推迟1秒钟。这确保了定期调用 wb_kupdate 将缓存数据与块设备同步,即使在 pdflush 子系统负荷很重时,也是如此。
}
```

# 超级块同步

超级块数据通过一个专用函数 sync_supers 进行同步。

```c
<fs/super.c>

void sync_supers(void)
{
	struct super_block *sb;

	spin_lock(&sb_lock);
restart:
	list_for_each_entry(sb, &super_blocks, s_list) {//遍历所有超级块
		if (sb->s_dirt) {
			sb->s_count++;
			spin_unlock(&sb_lock);
			down_read(&sb->s_umount);
			write_super(sb);//sb->s_op->write_super(sb);写入超级块
			up_read(&sb->s_umount);
			spin_lock(&sb_lock);
			if (__put_super_and_need_restart(sb))
				goto restart;
		}
	}
	spin_unlock(&sb_lock);
}
```

# inode 同步

```c
void
writeback_inodes(struct writeback_control *wbc)
{
	struct super_block *sb;

	might_sleep();
	spin_lock(&sb_lock);
restart:
	sb = sb_entry(super_blocks.prev);
	for (; sb != sb_entry(&super_blocks); sb = sb_entry(sb->s_list.prev)) {
		if (sb_has_dirty_inodes(sb)) {
			/* we're making our own get_super here */
			sb->s_count++;
			spin_unlock(&sb_lock);
			/*
			 * If we can't get the readlock, there's no sense in
			 * waiting around, most of the time the FS is going to
			 * be unmounted by the time it is released.
			 */
			if (down_read_trylock(&sb->s_umount)) {
				if (sb->s_root) {
					spin_lock(&inode_lock);
					sync_sb_inodes(sb, wbc);
					spin_unlock(&inode_lock);
				}
				up_read(&sb->s_umount);
			}
			spin_lock(&sb_lock);
			if (__put_super_and_need_restart(sb))
				goto restart;
		}
		if (wbc->nr_to_write <= 0)//指定的回写页的最大数目已经达到
			break;
	}
	spin_unlock(&sb_lock);
}
```

### 考察inode

所有脏inode置于特定于超级块的链表 super_block->s_dirty 上，该链表中的inode是按照时间逆序排列的。inode变脏的时间越靠后,它就越接近链表的尾部。

为对这些inode进行同步,还需要两个链表头。 super_block 结构的相关部分如下:

```c
<linux/fs.h>

struct super_block{
...
    struct list_head s_dirty; /* 脏inode的链表 */
    struct list_head s_io; /* 等待回写 */ //同步代码当前考虑回写的所有inode。
    struct list_head s_more_io; /* 等待回写,另一个链表 */
...
}
```

```c
<fs/fs-writeback.c>
static void
sync_sb_inodes(struct super_block *sb, struct writeback_control *wbc)
{
	const unsigned long start = jiffies;	/* livelock avoidance */

	if (!wbc->for_kupdate || list_empty(&sb->s_io))//区分两种情况，
	                                                //1.同步请求不是源于周期性机制：那么将脏链表上所有的inode都放置
	                                                //到 s_io 链表中。如果s_more_io 链表上有inode,则先将其置于 s_io
	                                                //链表的末尾。这种行为确保前一次同步剩余的inode仍然能够得到处理
	                                                //,但将优先考虑新近变脏的inode。（wbc->for_kupdate == 0）
	                                                //2.同步请求源于周期性机制(wbc->for_kupdate == 1)：
	                                                //仅当 s_io 链表为空时,才补充额外的脏inode。否则,内核将等待,直至 s_io 
	                                                //中所有inode的回写操作都完成为止。
		queue_io(sb, wbc->older_than_this);

	while (!list_empty(&sb->s_io)) {//遍历s_io链表
		struct inode *inode = list_entry(sb->s_io.prev,
						struct inode, i_list);
		struct address_space *mapping = inode->i_mapping;
		struct backing_dev_info *bdi = mapping->backing_dev_info;
		long pages_skipped;

		if (!bdi_cap_writeback_dirty(bdi)) {//纯粹基于内存的文件系统如RAM磁盘,或伪文件系统或纯粹的虚拟文件系统,都不需要与底层块设备同步 。
			redirty_tail(inode);//确保所s_dirty链表上的inode维持时间顺序
			if (sb_is_blkdev_sb(sb)) {//例外是：块设备伪文件系统 bdev,bdev 用于处理对裸块设备或其中分区的访问。对每个分区都提供了一个inode,对裸设备的访问通过该inode处理。
				/*
				 * Dirty memory-backed blockdev: the ramdisk
				 * driver does this.  Skip just this inode
				 */
				continue;
			}
			/*
			 * Dirty memory-backed inode against a filesystem other
			 * than the kernel-internal bdev filesystem.  Skip the
			 * entire superblock.
			 */
			break;
		}

		if (wbc->nonblocking && bdi_write_congested(bdi)) {//发生拥塞
			wbc->encountered_congestion = 1;//向更高层报告拥塞
			if (!sb_is_blkdev_sb(sb))
				break;		/* Skip a congested fs */
			requeue_io(inode);//当前inode属于块设备，使用辅助函数 requeue_io 将该 inode 从 s_io 移动到s_more_io 。（同一块设备的不同inode可能由不同的队列处理例如,在将多个物理设备合并为一个逻辑设备时。）
			continue;		/* Skip a congested blockdev */
		}

		if (wbc->bdi && bdi != wbc->bdi) {可以通过 writeback_control 指示 pdflush 专注于某一队列。如果遇到了一个使用不同队列的普通文件系统inode,则可以放弃处理。如果该inode表示一个块设备,则跳过该inode,去处理s_io 链表中的下一个inode,
			if (!sb_is_blkdev_sb(sb))
				break;		/* fs has the wrong queue */
			requeue_io(inode);
			continue;		/* blockdev has wrong queue */
		}

		/* Was this inode dirtied after sync_sb_inodes was called? */
		if (time_after(inode->dirtied_when, start))
			break;

		/* Is another pdflush already flushing this queue? */
		if (current_is_pdflush() && !writeback_acquire(bdi))
			break;

		BUG_ON(inode->i_state & I_FREEING);
		__iget(inode);
		pages_skipped = wbc->pages_skipped;
		__writeback_single_inode(inode, wbc);//回写
		if (wbc->sync_mode == WB_SYNC_HOLD) {//回写失败
			inode->dirtied_when = jiffies;
			list_move(&inode->i_list, &sb->s_dirty);
		}
		if (current_is_pdflush())
			writeback_release(bdi);
		if (wbc->pages_skipped != pages_skipped) {
			/*
			 * writeback is not making progress due to locked
			 * buffers.  Skip this inode for now.
			 */
			redirty_tail(inode);
		}
		spin_unlock(&inode_lock);
		iput(inode);
		cond_resched();
		spin_lock(&inode_lock);
		if (wbc->nr_to_write <= 0)
			break;
	}
	return;		/* Leave any unwritten inodes on s_io */
}
```

### 回写单个inode

```c
<fs/fs-writeback.c>
static int
__writeback_single_inode(struct inode *inode, struct writeback_control *wbc)
{
	wait_queue_head_t *wqh;

	if (!atomic_read(&inode->i_count))
		WARN_ON(!(inode->i_state & (I_WILL_FREE|I_FREEING)));
	else
		WARN_ON(inode->i_state & I_WILL_FREE);

	if ((wbc->sync_mode != WB_SYNC_ALL) && (inode->i_state & I_SYNC)) {//inode 被锁定
		struct address_space *mapping = inode->i_mapping;
		int ret;

		/*
		 * We're skipping this inode because it's locked, and we're not
		 * doing writeback-for-data-integrity.  Move it to s_more_io so
		 * that writeback can proceed with the other inodes on s_io.
		 * We'll have another go at writing back this inode when we
		 * completed a full scan of s_io.
		 */
		requeue_io(inode);//将其放入s_more_io链表中，这保证稍后会重新考虑

		/*
		 * Even if we don't actually write the inode itself here,
		 * we can at least start some of the data writeout..
		 */
		spin_unlock(&inode_lock);
		ret = do_writepages(mapping, wbc);//该inode有关的一些数据写出（因为这样没有什么害处。）
		spin_lock(&inode_lock);
		return ret;
	}

	/*
	 * It's a data-integrity sync.  We must wait.
	 */
	if (inode->i_state & I_SYNC) {//进行的是数据完整性回写，
		DEFINE_WAIT_BIT(wq, &inode->i_state, __I_SYNC);

		wqh = bit_waitqueue(&inode->i_state, __I_SYNC);
		do {
			spin_unlock(&inode_lock);
			__wait_on_bit(wqh, &wq, inode_wait,
							TASK_UNINTERRUPTIBLE);//等待该inode的I_SYNC标志被清除，
			spin_lock(&inode_lock);
		} while (inode->i_state & I_SYNC);
	}
	return __sync_single_inode(inode, wbc);
}
```

```c
static int
__sync_single_inode(struct inode *inode, struct writeback_control *wbc)
{
	unsigned dirty;
	struct address_space *mapping = inode->i_mapping;
	int wait = wbc->sync_mode == WB_SYNC_ALL;
	int ret;

	BUG_ON(inode->i_state & I_SYNC);

	/* Set I_SYNC, reset I_DIRTY */
	dirty = inode->i_state & I_DIRTY;
	inode->i_state |= I_SYNC;//锁定inode
	inode->i_state &= ~I_DIRTY;

	spin_unlock(&inode_lock);

	ret = do_writepages(mapping, wbc);//数据同步

	/* Don't write the inode if only I_DIRTY_PAGES was set */
	if (dirty & (I_DIRTY_SYNC | I_DIRTY_DATASYNC)) {
		int err = write_inode(inode, wait);//回写元数据
		if (ret == 0)
			ret = err;
	}

	if (wait) {
		int err = filemap_fdatawait(mapping);//该函数以页为单位等待写操作完成。当前即将回写到后备存储器的页会设置 PG_writeback 状态位,在负责回写的块层代码完成写操作之后,会自动清除该状态位。
		if (ret == 0)
			ret = err;
	}

	spin_lock(&inode_lock);
	inode->i_state &= ~I_SYNC;
	if (!(inode->i_state & I_FREEING)) {
		if (!(inode->i_state & I_DIRTY) &&
		    mapping_tagged(mapping, PAGECACHE_TAG_DIRTY)) {
			/*
			 * We didn't write back all the pages.  nfs_writepages()
			 * sometimes bales out without doing anything. Redirty
			 * the inode; Move it from s_io onto s_more_io/s_dirty.
			 */
			/*
			 * akpm: if the caller was the kupdate function we put
			 * this inode at the head of s_dirty so it gets first
			 * consideration.  Otherwise, move it to the tail, for
			 * the reasons described there.  I'm not really sure
			 * how much sense this makes.  Presumably I had a good
			 * reasons for doing it this way, and I'd rather not
			 * muck with it at present.
			 */
			if (wbc->for_kupdate) {
				/*
				 * For the kupdate function we move the inode
				 * to s_more_io so it will get more writeout as
				 * soon as the queue becomes uncongested.
				 */
				inode->i_state |= I_DIRTY_PAGES;
				requeue_io(inode);
			} else {
				/*
				 * Otherwise fully redirty the inode so that
				 * other inodes on this superblock will get some
				 * writeout.  Otherwise heavy writing to one
				 * file would indefinitely suspend writeout of
				 * all the other files.
				 */
				inode->i_state |= I_DIRTY_PAGES;
				redirty_tail(inode);
			}
		} else if (inode->i_state & I_DIRTY) {
			/*
			 * Someone redirtied the inode while were writing back
			 * the pages.
			 */
			redirty_tail(inode);
		} else if (atomic_read(&inode->i_count)) {
			/*
			 * The inode is clean, inuse
			 */
			list_move(&inode->i_list, &inode_in_use);
		} else {
			/*
			 * The inode is clean, unused
			 */
			list_move(&inode->i_list, &inode_unused);
		}
	}
	inode_sync_complete(inode);
	return ret;
}
```

# 拥塞

### 数据结构